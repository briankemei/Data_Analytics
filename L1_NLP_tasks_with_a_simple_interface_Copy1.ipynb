{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/briankemei/Data_Analytics/blob/main/L1_NLP_tasks_with_a_simple_interface_Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88535ead",
      "metadata": {
        "id": "88535ead"
      },
      "source": [
        "# L1: NLP tasks with a simple interface üóûÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6faa43ba",
      "metadata": {
        "id": "6faa43ba"
      },
      "source": [
        "Load your HF API key and relevant Python libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2698081-4deb-436a-a821-8ea48bdd6e6a",
      "metadata": {
        "height": 149,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "d2698081-4deb-436a-a821-8ea48bdd6e6a",
        "outputId": "4ad03c37-ec31-4f86-c969-053569c5a1e7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Hugging_api'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-703eae7889c0>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hugging_api'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhf_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hugging_api'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Hugging_api'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import io\n",
        "from IPython.display import Image, display, HTML\n",
        "from PIL import Image\n",
        "import base64\n",
        "from google.colab import userdata\n",
        "userdata.get('Hugging_api')\n",
        "hf_api_key = os.environ['Hugging_api']"
      ]
    },
    {
      "source": [
        "import os\n",
        "import io\n",
        "from IPython.display import Image, display, HTML\n",
        "from PIL import Image\n",
        "import base64\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve API key from userdata\n",
        "api_key = userdata.get('Hugging_api')\n",
        "\n",
        "# Check if the API key exists\n",
        "if api_key:\n",
        "    hf_api_key = api_key\n",
        "else:\n",
        "    # If not found in userdata, try getting it from environment variables.\n",
        "    # Make sure the environment variable exists and is named correctly.\n",
        "    if 'Hugging_api' in os.environ:\n",
        "        hf_api_key = os.environ['Hugging_api']\n",
        "    else:\n",
        "        print(\"Hugging Face API key not found. Please set it in userdata or as an environment variable.\")\n",
        "        hf_api_key = None # or handle the missing key appropriately"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_b7-u1bCgQZf"
      },
      "id": "_b7-u1bCgQZf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a106ab02-f248-4c03-9dd8-b1991db7f778",
      "metadata": {
        "height": 319,
        "collapsed": true,
        "id": "a106ab02-f248-4c03-9dd8-b1991db7f778"
      },
      "outputs": [],
      "source": [
        "# Helper function\n",
        "import requests, json\n",
        "\n",
        "#Summarization endpoint\n",
        "def get_completion(inputs, parameters=None,ENDPOINT_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL, headers=headers,\n",
        "                                data=json.dumps(data)\n",
        "                               )\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97a06f9",
      "metadata": {
        "id": "a97a06f9"
      },
      "source": [
        "## Building a text summarization app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
      "metadata": {
        "height": 268,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
        "outputId": "6b060766-c74a-448e-8c23-885b5c7cc08c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres (410 ft) on each side. It is the second tallest free-standing structure in France after the Millau Viaduct.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
        "        as an 81-storey building, and the tallest structure in Paris.\n",
        "        Its base is square, measuring 125 metres (410 ft) on each side.\n",
        "        During its construction, the Eiffel Tower surpassed the Washington\n",
        "        Monument to become the tallest man-made structure in the world,\n",
        "        a title it held for 41 years until the Chrysler Building\n",
        "        in New York City was finished in 1930. It was the first structure\n",
        "        to reach a height of 300 metres. Due to the addition of a broadcasting\n",
        "        aerial at the top of the tower in 1957, it is now taller than the\n",
        "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the\n",
        "        Eiffel Tower is the second tallest free-standing structure in France\n",
        "        after the Millau Viaduct.''')\n",
        "\n",
        "get_completion(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f144593f",
      "metadata": {
        "id": "f144593f"
      },
      "source": [
        "### Getting started with Gradio `gr.Interface`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRrHqJXT5K64",
        "outputId": "083f3d80-b258-43eb-f07f-02aceb6f0bc0"
      },
      "id": "vRrHqJXT5K64",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.10-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.10 ruff-0.6.7 semantic-version-2.10.0 starlette-0.38.6 tomlkit-0.12.0 uvicorn-0.30.6 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")\n",
        "# Use the port number 7860 directly\n",
        "demo.launch(share=True, server_port=7860)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "vDYcAfnm56N6",
        "outputId": "0e4f4c00-f6bb-4ba9-cbf9-8ce9c875abd8"
      },
      "id": "vDYcAfnm56N6",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://fc20fe9f59dbeb2fce.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fc20fe9f59dbeb2fce.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b310770",
      "metadata": {
        "id": "9b310770"
      },
      "source": [
        "`demo.launch(share=True)` lets you create a public link to share with your team or friends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "60684b55-c7ae-4c9e-88ea-bbc2e702ecdb",
      "metadata": {
        "height": 268,
        "id": "60684b55-c7ae-4c9e-88ea-bbc2e702ecdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "e03c53a7-c3a9-442f-9151-c5f0341aaa3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://2a6274b5e66726c254.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2a6274b5e66726c254.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=summarize,\n",
        "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
        "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
        "                    title=\"Text summarization with distilbart-cnn\",\n",
        "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
        "                   )\n",
        "demo.launch(share=True,server_port=7860)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b300d17",
      "metadata": {
        "id": "4b300d17"
      },
      "source": [
        "## Building a Named Entity Recognition app"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d1043f",
      "metadata": {
        "id": "c0d1043f"
      },
      "source": [
        "We are using this [Inference Endpoint](https://huggingface.co/inference-endpoints) for `dslim/bert-base-NER`, a 108M parameter fine-tuned BART model on the NER task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f663dcbb",
      "metadata": {
        "id": "f663dcbb"
      },
      "source": [
        "### How about running it locally?\n",
        "\n",
        "```py\n",
        "from transformers import pipeline\n",
        "\n",
        "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "\n",
        "def ner(input):\n",
        "    output = get_completion(input)\n",
        "    return {\"text\": input, \"entities\": output}\n",
        "    \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db4a922-b300-4dbc-8768-955b6a18dce4",
      "metadata": {
        "height": 81,
        "id": "0db4a922-b300-4dbc-8768-955b6a18dce4"
      },
      "outputs": [],
      "source": [
        "API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n",
        "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
        "get_completion(text, parameters=None, ENDPOINT_URL= API_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5f60b3-bdf0-4b96-a387-7a48b9017ca7",
      "metadata": {
        "id": "bd5f60b3-bdf0-4b96-a387-7a48b9017ca7"
      },
      "source": [
        "#### gr.interface()\n",
        "- Notice below that we pass in a list `[]` to `inputs` and to `outputs` because the function `fn` (in this case, `ner()`, can take in more than one input and return more than one output.\n",
        "- The number of objects passed to `inputs` list should match the number of parameters that the `fn` function takes in, and the number of objects passed to the `outputs` list should match the number of objects returned by the `fn` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c21254-128d-446c-b6dd-e30af26d436d",
      "metadata": {
        "height": 268,
        "id": "e5c21254-128d-446c-b6dd-e30af26d436d"
      },
      "outputs": [],
      "source": [
        "def ner(input):\n",
        "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
        "    return {\"text\": input, \"entities\": output}\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=ner,\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
        "                    title=\"NER with dslim/bert-base-NER\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
        "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT3']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f16ad4",
      "metadata": {
        "id": "60f16ad4"
      },
      "source": [
        "### Adding a helper function to merge tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc278e9-87b4-420b-89e9-7120dc4be754",
      "metadata": {
        "height": 540,
        "id": "4dc278e9-87b4-420b-89e9-7120dc4be754"
      },
      "outputs": [],
      "source": [
        "def merge_tokens(tokens):\n",
        "    merged_tokens = []\n",
        "    for token in tokens:\n",
        "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
        "            # If current token continues the entity of the last one, merge them\n",
        "            last_token = merged_tokens[-1]\n",
        "            last_token['word'] += token['word'].replace('##', '')\n",
        "            last_token['end'] = token['end']\n",
        "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
        "        else:\n",
        "            # Otherwise, add the token to the list\n",
        "            merged_tokens.append(token)\n",
        "\n",
        "    return merged_tokens\n",
        "\n",
        "def ner(input):\n",
        "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
        "    merged_tokens = merge_tokens(output)\n",
        "    return {\"text\": input, \"entities\": merged_tokens}\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=ner,\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
        "                    title=\"NER with dslim/bert-base-NER\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT4']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010",
      "metadata": {
        "height": 30,
        "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010"
      },
      "outputs": [],
      "source": [
        "gr.close_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cac5cd66-b6c2-4a01-a06a-44ba0c4c7394",
      "metadata": {
        "id": "cac5cd66-b6c2-4a01-a06a-44ba0c4c7394"
      },
      "source": [
        "## How to get your own Hugging Face API key (token)\n",
        "\n",
        "Hugging Face \"API keys\" are called \"User Access tokens\".  \n",
        "\n",
        "You can create your own User Access Tokens here: [Access Tokens](https://huggingface.co/settings/tokens).\n",
        "\n",
        "#### Save your user access tokens to environment variables\n",
        "To save your access token securely on your own machine:\n",
        "- Create a `.env` file in the root directory of your project.\n",
        "- Edit the file to contain the following:  \n",
        "`HF_API_KEY=\"abc123\"` replace that string with your user access token.\n",
        "- Save the .env file.\n",
        "- Install Python-dotenv, which allows you to run that first code cell at the top of this jupyter notebook:  \n",
        "`pip install python-dotenv`\n",
        "\n",
        "\n",
        "For more information on how to get your own access tokens, please see [User access tokens](https://huggingface.co/docs/hub/security-tokens#:~:text=To%20create%20an%20access%20token,you're%20ready%20to%20go!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a5a409",
      "metadata": {
        "height": 30,
        "id": "f7a5a409"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}